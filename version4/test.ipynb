{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from model import Model\n",
    "from retriever import Retriever\n",
    "from prompts import get_prompt, combined_template, interp_template\n",
    "from agent import RAGAgent, InterpAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('random_sample.csv') \n",
    "#model = Model(model_name=\"llama3.3\")\n",
    "#model = Model(model_name=\"qwen:32b\")\n",
    "model = Model(model_name=\"mistral\")\n",
    "#retriever = Retriever(\"schema\", 'embed', embed_model_name=\"all-MiniLM-L6-v2\", df=df)\n",
    "retriever = Retriever('hybrid', embed_model_name=\"all-MiniLM-L6-v2\", db=FAISS)\n",
    "prompt = get_prompt(combined_template)\n",
    "\n",
    "processor = RAGAgent(retriever, prompt, model, df)\n",
    "interp_prompt = get_prompt(interp_template)\n",
    "interp = InterpAgent(interp_prompt, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': \" ```python\\n   df['writing score'].sort_values().head(2)\\n   ```\", 'result': 11    22\n",
      "9     41\n",
      "Name: writing score, dtype: int64}\n",
      "The question: What are the two lowest writing scores?\n",
      "   The relative result: {'code': \" ```python\\n   df['writing score'].sort_values().head(2)\\n   ```\", 'result': 11    22\n",
      "9     41\n",
      "Name: writing score, dtype: int64}\n",
      "\n",
      "The concluding response: According to the provided code and result, the two lowest writing scores are 11 and 22. These scores are associated with the row numbers 9 and 41 in your dataframe. It is essential to note that further context or additional analysis might be required for a comprehensive understanding of these scores within your dataset.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "query = \"What are the two lowest writing scores?\"\n",
    "ctx = processor.invoke(query,\n",
    "                        temperature=0.3,\n",
    "                        top_p=0.9,)\n",
    "answer = interp.invoke(ctx, query,\n",
    "                        temperature=0.8,\n",
    "                        top_p=0.9,)\n",
    "print(ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单直接的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': \" ```python\\n   df['math score'].max()\\n   ```\", 'result': 91}\n",
      "The question: What is the highest math score?\n",
      "   The relative result: {'code': \" ```python\\n   df['math score'].max()\\n   ```\", 'result': 91}\n",
      "   The concluding response: Based on the provided Python code and its output, it can be concluded that the highest math score is 91.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the highest math score?\"\n",
    "ctx = processor.invoke(query,\n",
    "                        temperature=0.3,\n",
    "                        top_p=0.9,)\n",
    "answer = interp.invoke(ctx, query)\n",
    "print(ctx)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What is the lowest reading score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What are the two lowest writing scores?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"How many students whoes reading score more than 80?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综合问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': \" ```python\\n   df.groupby('gender')['math score'].mean()\\n   ```\",\n",
       " 'result': gender\n",
       " female    60.375000\n",
       " male      66.166667\n",
       " Name: math score, dtype: float64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.invoke(\"Which gender has a better math score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"If parental level of education has the impact for reading score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What's the best comprehensive score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What're the features of the student who has the best writing score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What're the features of the student who has the best total score?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要分析的综合问题，回答的不好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字段近似表述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code execution error: Invalid syntax in code: result = from sklearn.preprocessing import OneHotEncoder\n",
      "   enc = OneHotEncoder(sparse=False)\n",
      "   df['lunch'] = enc.fit_transform(df[['lunch']])\n",
      "   corr_matrix = df[['writing score', 'lunch']].corr()\n",
      "   print(corr_matrix)\n",
      "Error: invalid syntax (<string>, line 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'code': \" ```python\\n   df.groupby('lunch')['writing score'].mean()\\n   ```\",\n",
       " 'result': lunch\n",
       " free/reduced    65.7\n",
       " standard        62.2\n",
       " Name: writing score, dtype: float64}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.invoke(\"If food impacts writing score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"If students who completed preparation have a better writing score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"Which racial has the best writing score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['reading score', 'writing score', 'math score']].sum(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现：\n",
    "1、如果result的值为None重新执行processor.invoke(query)\n",
    "2、根据用户的query和processor.invoke(query)的结果，用一个新的总结提炼模型来用自然语言回答用户的问题，而不是只给code\n",
    "3、如果2提供的信息使你无法总结提炼来回答query，则重新执行processor.invoke(query)，直到步骤2能顺利进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from version4.model import Model\n",
    "from retriever import Retriever\n",
    "from template import get_prompt, combined_template\n",
    "from agent import ChainProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('product_sample.csv')\n",
    "model = Model(model_name=\"llama3.1\")\n",
    "retriever = Retriever(\"schema\", 'embed', embed_model_name=\"all-MiniLM-L6-v2\", df=df)\n",
    "prompt = get_prompt(combined_template)\n",
    "processor = ChainProcessor(retriever, prompt, model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What's the worst average rating?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What's the best satisfaction?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What's the average inventory?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"Which product has the highest sales volume?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"How many products are currently on promotion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.invoke(\"What're the features of product which has the best market feedback?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
